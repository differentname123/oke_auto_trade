2024-12-08:
    已完成:
        1.简单的合约下单，以1h内的最高和最低作为看空和看多的依据
    待完成:
        1.思考一个稳定的下单价格和卖出的策略。

2024-12-11:
    已完成:
        1.尝试Transformer训练btc的数据（效果很差基本就和随机的效果一样）,感觉调整sequence_length能够改善效果
    待完成:
        1.思考一个稳定的下单价格和卖出的策略。

2024-12-12:
    已完成:
        1.不同参数情况下找寻好的模型。
        2.poe机器人的本地访问。
        3.租用服务器部署到服务器上能够访问了。
    待完成:
        1.采用一个稳定的下单价格和卖出的策略。
        2.优化转发的逻辑和页面 。

2024-12-13:
    已完成:
        1.0.01个点的量化交易（看起来还不错，模拟的手续费太高了导致没盈利）
        2.模型训练的优化（采用更复杂的模型组合 + 更多的特征）
    待完成:
        1.应用0.01个点的量化交易到实盘中。
        2.遍历更多的参数，找到更好的模型。

2024-12-14:
    已完成:
        1.优化量化交易的代码:(1.实时价格相对上次变化了才下单 2.下单失败后自动取消两个委托单 3.应对单方面变化的情况调整最大占比与调整买入 盈利偏移量)，由于手续费的原因，至少盈利0.07（买入:0.02 卖出：0.05）个点才行。
    待完成:
        1.应用0.01个点的量化交易到实盘中。
        2.遍历更多的参数，找到更好的模型。
        3.优化存在一部分单子对应的止盈单丢失的情况。
        4.目前这个逻辑是不是会出现极端高价或者低价的单子，运行模拟盘看看情况吧
        5.采用websockt的方式获取实时价格，能够提高速度。
        6.发现了现在优化后的问题，感觉不能够按照目前的比例来进行调整，应该按照变化的比例来调整。目前存在一个问题，那就是：
            如果目前累计了很多看空单，理论上就会加大看多单的盈利，但是如果现在虽然看空单还是很多，但是已经在减小，走下坡了，那么久不应该调高盈利，不然大概率无法卖出。所以就应该价格也在增加，看空单也在增加的情况下才调高盈利。


2024-12-15:
    已完成:
        1.取消某一方向单子多的时候不再买入的逻辑。（这样会导致价格倒挂：空单的均价会低于多单的均价）
        2.部署智言到服务器开放使用对话功能。
        3.尝试了一下200seq训练出来的模型，感觉在高阈值下做出的判断还比较可以。
        4.单独获取数据的模型性能报告的实现（还需要联合训练的代码进行相应的规范，现在太乱了）
        5.更新当前量化交易的策略说明，方便后续分析问题进行改进。
    待完成:
        1.应用0.01个点的量化交易到实盘中。
        2.继续思考优化后的量化策略（如何避免在跌幅买入大量空单 如何避免在涨幅高位买入大量多单）
        3.尝试多参数+不同数据找到不同的好模型，然后进行集成判断做出最稳定的决策。
        4.量化交易代码的优化：
            1.优化存在一部分单子对应的止盈单丢失的情况。
            2.采用websockt的方式获取实时价格，能够提高速度。
            3.如果目前累计了很多看空单，理论上就会加大看多单的盈利，但是如果现在虽然看空单还是很多，但是已经在减小，走下坡了，那么久不应该调高盈利，不然大概率无法卖出。所以就应该价格也在增加，看空单也在增加的情况下才调高盈利。

2024-12-17:
    已完成:
        1.量化交易：
            1.采用更大的买入偏差和盈利偏差，避免在高位买入。
            2.采用更大的惩罚偏差，避免多 空 单太过失衡。
            3.增加丢失单设置止盈单的逻辑。
            4.确保限价单价格分布的合理性。（不能大量同一价格的单子集中在一起）
    待完成：
        1.尝试计算出多 空不平衡状态下，如何调整盈利值才能保证利润最大。
        2.重新实现买入的策略：每次都将资金全部规划用出去，然后根据实际的买入卖出情况进行调整。

2024-12-17:
    已完成:
        1.量化交易，完整的平衡思路（应对单向变化的问题）：
            核心：根据多空仓位来决定买单的价格，进行惩罚性的调整。
            流程:
                1.获取持仓信息，多空比例，和可用资金。

        2.数量相关的都保留1位小数
        3.下单时会增加两个移动止盈止损
        4.增加止盈的方式是取最能够成功的那种。撤销时间太久的止盈单子。

    待完成:
        1.继续分析可能出现的问题，进行相应的调整。
        2.思考合适的模型训练的目标变量，以及后续的融合判断方案。




2024-12-19:
    已完成:
        1.量化交易：
            1.实盘采用差距更大的买入条件，后续使用不爆仓的方式进行调整。
            2.参数空间寻找最优模型。和加载模型进行预测。（还有问题）
    待完成:
        1.直接使用模型来判断买入的条件（但是目前服务器环境不支持，如果效果好的话就步数到服务器）
        2.服务器上可以采用一次性挂出所有买单的方式。
        3.参数空间寻找最优模型还存在一点问题：单独运行已经训练成功的数据会有一点准确率的出入，不晓得哪有问题
        4.不同目标函数模型结果的融合，助力最终的判断。

2024-12-20:
    已完成:
        1.量化交易：
            1.采用模型的买入信号。
            2.模型结果融合的分析：
                能够加大准确率的方法：
                    1.取置信度高的几个数据。
                    2.相似目标变量进行求和然后用于判断（效果看起来不错）：求和取前面部分会比较稳定。先取前面再交集会，涉及到的距离就更远。解释：如果直接使用两个目标变量的和来排序，比如到0.03就有106个数据，效果为0.71。如果先分别计算每个目标变量的前面部分，然后再取交集，到0.075的效果是0.7，数据有89个

    待完成:
        1.实时买入还应该优化最新的数据，目前延时一分钟，导致不够及时。
        2.使用融合的结果进行量化交易

2024-12-20:
    已完成:
        1.量化交易：
            1.模型结果融合的分析：
                能够加大准确率的方法：
                    1.融合模型不是越多越好，应该需要有一定的相似性。，在附近才能够很好的提升准确率
    待完成:
        1.后续跑多个模型，然后按照之前的规则进行多种融合，选择出相应的策略。
        2.现在策略的信号太少了。一天都没一个信号。

2024-12-23:
    已完成:
        1.量化交易：
            1.增加模型的融合策略，遍历每个目标，生成历史数据上的胜率。
            2.根据融合的策略进行最新数据的分析，生成每个目标下的概率。
            3.找寻不同参数（利润差距 时间差距）下每个目标最好的表现。
            4.为提高及时性，目前只对score大于0.1的目标进行预测
    待完成:
        1.确定一下是否是正常的没有问题。
        2.优化性能，还需要找到更好的组合融合方式（1.直接从每个模型的测试报告入手 2.尝试不同目标区间的表现结果）。
        3.目前是找的0.8概率以上的机会，后续增加高利润低成功率的目标。
        4.为提高准确性，找找寻不同参数（利润差距 时间差距）下每个目标最好的表现的历史数据进行扩大。（当前是5000行）

2024-12-23:
    已完成:
        1.量化交易：
            1.找寻不同参数下模型历史数据上的效果。
            2.找到新的模型融合策略，（每个模型预测后，分析阈值低的方向是否统一，然后使用概率最大的那个作为利润参考）
    待完成:
        1.每个模型预测后，分析阈值低的方向是否统一，然后使用概率最大的那个作为利润参考
        2.融合的时候应该采用不同的子融合项目，不然就没有独立的效果。
        3.现在怎么使用全量的策略去分析，怎么还会存在比使用部分分析的结果少的情况。
        4.使用模型效果并不好，后续还是使用传统的rsi和macd吧

2024-12-27:
    已完成:
        1.量化交易:
            1.重新使用简单的指标来进行信号的生成（基本都是一级指标，没有进行组合）

    待完成:
        1.继续完善指标的生成，目前已经优化了指标17和指标16（下面生成信号的代码是否会使用未来的数据？它最多依赖多久的历史数据？还能不能生成相应更多的信号，我想找到最好的信号，注意买入信号必须包含_Buy,卖出信号必须包含_Sell,过程生成的字段注意删除,但是不能删除原本df的数据。）
        2.根据数据指定相应的买入和止盈策略（买入时应该偏差多少：需要根据历史信号产生的未来1m的最大和最小涨幅来决定，因为不能一味的更低买入，因为可能会错过直接上涨的数据），止盈的价格也需要根据历史数据来决定，以历史数据为准，采取最大的盈利。
        3.还可以尝试不同时间段的融合，比如1h显示会下跌，那么细化到1m久尽量做空，如果1h显示会上涨，那么细化到1m久尽量做多。

2024-12-28:
    已完成:
        1.量化交易:
            1.能够提高效果的融合方式是保证每个模型的独立性，然后再进行融合。
            2.重新统一拉取数据 进行回测 分析回测报告 实战使用
    待完成:
        1.还需要增加目标列表示未来时间的涨跌幅，方便进行不同时间的融合。
        2.还有就是如何抓住异常的数据(买入后未成功，是不是应该再加大买入的力度)
        3.还得重新生成相应的特征信号，感觉简单的反而是有效的，比如（创造一段时间内的极值，并开始反转）

2024-12-29:
    已完成:
        1.量化交易:
            1.实盘 模拟盘使用260周期极值交易。
    待完成:
        1.继续找好的策略，然后进行实盘测试。

2025-01-01:
    已完成:
        1.量化交易:
            1.建立完整的回测系统，能够进行回测，分析回测报告，实战使用。不然总会爆仓。
            回测系统详细设计如下:
                1.先为待回测数据生成相应的买入获取卖出信号，需要指定相应的买入价和卖出价格。
                2.按照时间顺序进行回测。
                    1.检测当前的委托单，根据最高价和最低价进行相应的处理，调整相应的仓位信息。
                    2.检测是否有买入或者卖出信号，有的话生成相应的委托单子。
                    3.委托单的失效处理，如果超过一定时间还没有成交，那么就取消。
                    维护相应的开仓和平仓委托单，同时考虑当前的持仓情况。这样才能够保证回测的真实性。
    待完成:
        1.继续找好的策略，然后进行实盘测试。
        2.可以再确定一下是否是正常的没有问题。

2025-01-01:
    已完成:
        1.量化交易:
            1.优化之前的数据回测函数，增加了0.01到0.05分位的值。
            2.回测系统进行优化：规范数据的拉取 输出结果的格式。
            3.好的策略需要考虑不同趋势的盈利结果（比如需要找到在 上涨 震荡 下跌 都能够盈利的结果）。
            4.手动增加三种趋势的训练。
    待完成:
        1.寻找好的策略，然后进行实盘测试。（目前基本上以及跑完了price_extremes的策略）
        2.为了找到最稳定的结果，需要实现自动失败趋势，然后获取三个趋势的盈利结果，然后进行融合，比较。

2025-01-03:
    已完成:
        1.量化交易:
            1.开始寻找不同币下面的价格极值策略的表现。
    待完成:
        1.补充出现滑点导致止盈单丢失的情况。
        2.探索其它策略的表现，甚至反着信号进行买卖。

2025-01-04:
    已完成：
        1.量化交易：
            1.重数据看起来是如果价格创造极值之后突破的概率还会更大一些。
            2.现在能够直接跑出4种币数据的极值策略。
            3.预回测的数据增加平均值这一项。

    待完成：
        1.继续寻找好的策略，然后进行实盘测试。
        2.尝试大规模的un极值策略
        3.确定当前的ton策略是否是ok的
        4.思考是否能够实现得到历史数据的所有回测结果，然后能够任意的得到区间的回测表现，这样就能够更好的评测策略的性能了。


2025-01-09:
    已完成：
        1.量化交易：
            1.全量跑历史数据，然后获取任意区间的表现（思路是错误的，并不能够在减少时间复杂度的情况下，实现任意区间的表现获取）:
                1.历史过程df需要记录下每个时间段的动作，包括买入和卖出。
                2.再来一个统计函数，输入时间段和历史df，便可以计算出该区间的表现。

    待完成：
        1.继续寻找好的策略，然后进行实盘测试。
        2.是否有必要单独使用buy和sell的信号，而不是绑定使用
        3.使用ma信号进行找寻
        4.改造回测系统，让它更加灵活（1.时间段可获取效果 2.输出结果更加规范 3.能够支持同时买和卖 4.count也能够灵活变化 5.重新思考max_cost的计算逻辑）
            详细步骤:
                1.提前为每一行数据生成不同偏移比例平仓的时间戳（考虑是否要跳过接下来的第一行，因为 假如再n时间产生开仓信号 只能在n+1时间开仓，如果n+1时间产生指定的偏移，能在n+1平仓吗（应该是能够的，因为偏移量大概率比开仓的价格更远，所以开仓大概率更先））
                2.回测的时候就筛选出指定时间段有交易信号的行，并且再一步筛选出真实能够开仓的列，然后分别计算（最大资金使用率 利润 利润率 交易比例 持有时间 ）
                3.重新换种找好信号的方式，不用每个都计算详细的过程的数据，可以先进行一波筛选，筛选逻辑如下：
                    1.直接使用信号的时间戳，找到对应的原始数据，然后获取这一个信号在指定时间段，指定目标变量的表现（平均持有时间 利润 持仓）
                4.在表现比较好的信号上，再进行详细的回测，获取最好的回测结果。



2025-01-10:
    已完成：
        1.开始运行极值信号在预处理数据上面的大概回测效果
    待完成：
        1.当前的信号并没有考虑无法买入的情况。
        2.现在直接处理的是所有时间段的情况，未分时间段来获取相应的表现。
        3.思考找到好结果的方式。

2025-01-13:
    已完成：
        1.完成初步的评估方法，能够选择出好的信号。
    待完成：
        1.重构买入的系统，以应对后续灵活的买入情况
        2.将好的信号放入回测系统中，获取效果。
        3.完成更多的信号效果评测。

2025-01-15:
    已完成：
        1.考虑时间段的评分方式，能够更好的评估信号的效果。
        2.使用media来计算评分感觉不太合理，因为holdtime的重要性，影响到了资金卡死。
        3.多时间的评分感觉不能只是使用简单的求和，现在的分析方式能够体现holdtime的重要性，但是感觉无法体现profit的重要性(增加了除以（0.11 - profit）)
    待完成：
        1.重构买入的系统，以应对后续灵活的买入情况.（1.考虑止盈止损数量超过50的情况  2.资金不够使用的情况 3.拉取数据失败的问题）
        2.将好的信号放入回测系统中，获取效果。
        3.完成更多的信号效果评测。

2025-01-16:
    已完成：
        1.思考有无必要将median换成更大的阈值，比如0.9
        2.新增更加对初步筛选后好策略更加详细的获取结果（增加持有最大时间与卖出的倍率）
    待完成:
        1.考虑售出的策略，感觉不能够一直持有。超时的直接在下一个反的信号卖出.(重新考虑售出的价格，也可以直接调整 max_diff_time和profit来找最好的参数)
        2.考虑同时买入多种币的情况（因为走势有比较大的类似）
        3.highest_100_sell 和 highest_1000_sell是包含关系，可以考虑这个区间的表现。
        4.对详细的回测结果中选择好的策略投入最终的使用。

2025-01-18:
    已完成：
        1.完成一部分的好策略的详细回测结果。
        2.完成部分下单系统的优化（目前能够直接加载好策略的数据并进行相应的下单）
    待完成：
        1.完成所有结果的回测
        2.优化最终的下单系统
        3.现在详细的回测遇到积压很多的请款会出现运行特别久的情况（考虑 1.更细力度的执行，而不是每个策略所有的细力度执行 这样能够最大可能的提高效率）
        4.新增信号（单周期振幅超过某个阈值）
        5.考虑假如都买入的情况。这个思路是来源于：（当一个比较看好的信号出现积压的时候通常都会等到价格回暖才会卖出去，那么是已经默认价格还会上涨，是不是就应该放宽买入的条件，积极的做多呢）。所以这个思路的步骤就算判断假如都买入的时候，根据卡单的情况，来决定是否买入（放大买入的条件）。


2025-01-19:
    已完成：
        1.思考更小资金占用的交易方式（顺势而为:上涨的时候就开多，下跌的时候就开跌）：
            分析：
            1.开多之后有三种走势:上涨，下跌，震荡
        2.修复售出系统，不撤回平仓单子。
        3.验证了新思路的可行性，能够在一定程度上提高盈利。（顺势而为 + 及时止损：这是一个基于前一日最高价和最低价进行突破交易的策略。当价格突破前一日的低点时，平多开空；当价格突破前一日的高点时，平空开多。第一个交易日默认开多仓。且1m的数据基本上都会亏钱）
    待完成：
        1.顺势而为加上价格的阈值反而效果更差（因为也抹杀了卖更多钱的可能性）,反而在极大值生成做多，极小值生成做空的情况下效果更好。
        2.再进一步验证策略的可行性，看看是否有什么遗漏的情况。
        3.看起来1m上的数据很少能够跑过手续费而盈利的，所有可以思考之前使用1m数据的策略是否可以改进

2025-01-21:
    已完成：
        1.突破策略的实现，详细逻辑如下:
        2.突破的策略回测的结果不太正确，之前的之间不亏损的fix方法完全不正确，因为不符合实际操作，如果放在实际操作就会变成，一旦开多，如果价格继续降低，那么就会触发平仓（好像也不是不行啊,只追求单向的可能效果也不错）
        3.增加极值好策略的运行
    待完成：
        1.突破策略的回测方法还需要进一步的优化，现在感觉存在和实际不相符的情况，可能会极大影响回测的结果。

2025-02-07:
    已完成：
        1.突破策略的实现。
    待完成:
        1.增加最大亏损，方便计算合理的杠杆。
        2.根据最大亏损和最大利润，确定相应的杠杆，以及最后的盈利

2025-02-08:
    已完成：
        1.优化执行的速度
    待完成：
        1.实盘运行策略
        2.找寻其它的突破参数（固定值）

2025-02-09:
    已完成：
        1.分批次执行，提高执行速度，避免内存太大与出问题需要完全重新执行。
        2.计算每个参数对应的最优杠杆与收益
    待完成：
        1.实盘运行策略
        2.找寻其它的突破参数（固定值）

2025-02-10:
    已完成：
        1.增加失败率与失败时间占比
    待完成：
        1.实盘运行策略
        2.找寻其它的突破参数（固定值）
        3.思考如何解决失败率都比较高的问题与扩展性不强的问题（扩展性不强：在一个数据上表现很好，但是在新数据上表现就很平平无奇，甚至巨额亏损，太依赖偶然一次的大幅度盈利）

2025-02-11:
    已完成：
        1.分析扩展性不强的问题（因为历史数据中存在偶然的大利润，导致最终的利润很好看，其实该参数大部分都是亏钱的状态），可以尝试去掉最高利润重新进行相关参数的计算
        2.如果要求扩展性强，那么就应该在历史数据是明显单次盈利（avg_profit_rate需要比较大的情况下） 且验证的时间比较长，所以为了提高扩展性，应该看重这几个参数：1.失败率（我觉得还可以加上2，3，4等周期和的失败率）。2.偏离率（最终的盈利是不是由少数极端影响的，如果是的话那就代表平时大多数时间都在亏损）
        3.增加连续周期利润和的失败率
    待完成：
        1.思考加入其它的突破参数（固定值）和未完成的相对值

2025-02-11:
    已完成：
        1.规范信号的命名，增加连续上涨或下跌的突破信号/
        2.bread_through_strategy_debug.py目前loss_rate小于0.6的基本上能够在未来不亏钱。
    待完成：
        1.增加剩余的三种信号。
        2.继续解决拓展性不强的问题。

2025-02-13:
    已完成：
        1.增加利润的标准差，方便计算夏普率
        2.在将'BTC', 'ETH', 'SOL', 'TON'四个数据都为正的参数融合后，发现按照kai_count差值小排序的效果不错（感觉发现了好东西）。
        3.感觉从好参数里面分析特征更容易找到真正的好参数，上面的规律就是偶然发现表现好的参数，kai_min和kai_max差值很小发现的，所有后续还应该多多从好的结果中发现规律这种方法。
        4.增加指定周期上涨或者下跌超过固定值的信号。
    待完成：
        1.继续解决拓展性不强的问题（研究一下上面说到的情况）。
        2.继续寻找好的策略。
        3.增加更多的信号。

2025-02-14:
    已完成：
        1.修复增加指定周期上涨或者下跌超过固定值的信号，信号出问题了，空欢喜一场。但是发现abs相关的效果确实不错
        2.优化效率，跳过20数量以下的数据
        3.增加不规则遍历的方式，能够更好的找到好的参数（不是均匀的step而是指数级别的增长）
        4.全量组合，不再忽略任何的参数
    待完成:
        1.增加更多的信号。
        2.可以进入实盘操作了。


2025-02-15:
    已完成：
        1.完成5种信号的统一找寻
    待完成：
        1.选择出好的策略，可尝试取都盈利的组合
        2.增加更多的信号（再思考有无其它的方法）。


2025-02-17:
    已完成：
        1.又增加两种信号总共7种信号

    待完成：
        1.再增加一些个参数，叫做max_profit,和min_profit(即最大亏多少或者赚多少直接提前平仓)
        2.测试盘运行好的信号

2025-02-18:
    已完成：
        1.实盘运行四个币种的好策略（基本上都是peak_1 和 abs_1_0.5 这种参数的结果比较好）
        2.发现了大问题，需要重新跑数据（之前的未进行过滤，如果同一个时间平仓之后是不能够开仓的）
        3.有利于找到好参数的评判标准（1.多除std有利于稳定性 2.统计kai_column和pin_column出现的个数，选择个数多的）

    待完成：
        1.因为之前的回测逻辑有漏洞，现在需要全部重新跑一遍数据

2025-02-19:
    已完成：
        1.发现reverse里面有好的参数，需要验证是不是这样的。
        2.数量要达到一定的值感觉稳定性很高（比如 net_profit 大的 且 kai_count也大的）
        3.回测的逻辑还是需要调整，因为不能够简单的删除pin和开在同一个时间的数据，开仓信号必须和平仓信号互斥，不然会出现问题，会利用未来的数据(增加same_count参数，表示开仓信号和平仓信号在同一个时间的个数 进行同时开仓平仓的修复，价格调整到相同的数据)。
    待完成：
        1.继续寻找好的参数以及排序方法

2025-02-20:
    已完成：
        1.实盘在跑sol的三个参数。
        2.后续改成每个信号单独组合，先分别找出比较不错的信号再进行后续的组合。
        3.每种信号策略的生成都还有不小的变换空间，特别是关于 上穿或者下穿时，上一个比较价格的选取， close high low open 这几种都可以变化
    待完成：
        1.每个策略单独运行，找出比较好的策略，而且取消全量组合的方式（因为重合率太高了）。

2025-02-21:
    已完成：
        1.先单独运行不同的策略
        2.增加时间分布的统计，能够提高稳定性
    待完成：
        1.优化好参数的选择（注意需要剔除相似性很高的参数（特别是下单时间和平仓时间基本上相同的数据）还需要选择独立互补的好参数）
        2，尝试自动化的选择出好的参数


2025-02-22:
    已完成：
        1.增加每个月的统计信息
        2.分离回测与debug的代码
    待完成：
        1.完成新回测结果的生成。
        2.微调不同信号生成更多的参数。


2025-02-23:
    已完成：
        1.直接综合生成所有的组合方式。
        2.增加综合评分策略（利润得分 + 稳定性得分），选择出比较好的策略
    待完成：
        1.跑出BTC的全部参数组合，进行实盘运行
        2.优化综合评分策略。

2025-02-25:
    已完成：
        1.考虑增加更加真实的情况，当信号再次发生，并且成本价格更加好时，继续买入。
        2.考虑在亏损的时候是否要联合其它的策略进行加仓。
        3.超级优化回测的速度
    待完成：
        1.继续优化综合评分策略。
        2.继续跑出BTC的全部参数组合，进行实盘运行
        3.更多参数组合的回测结果获取


2025-02-26:
    已完成：
        1.回测数据增加每个月的交易量与盈利值（方便后续进行相关性的计算）
    待完成:
        1.获取新参数下面的回测结果。


2025-02-27:
    已完成:
        1.增加参数间关联性分析。
        2.更加细力度的参数结果获取。
    待完成：
        1.选择出能够对冲的信号

2025-02-28:
    已完成:
        1.更新下单的信号产生方式（现在更加合理）
        2.优化下单系统，增加对订单信息的保存，方便中断后继续
    待完成：
        1.还是需要生成相同方向不同信号的组合
        2.根据已有的好参数进一步的仔细搜素

2025-03-01:
    已完成:
        1.粗略的生成逆向数据
    待完成：
        1.还是需要生成相同方向不同信号的组合
        2.根据已有的好参数进一步的仔细搜素

2025-03-01:
    已完成:
        1.生成好参数的更细力度的数据
    待完成：
        1.为sol较好的数据(包括粗略的逆向数据)生成更加细力度的数据
        2.根据相关度选择出比较独立的一组参数.

2025-03-03:
    已完成:
        1.优化实时下单的逻辑(优化日志,修复只根据判断方向来进行做多和做空的判断)
    待完成:
        1.增加sol的逆向数据实盘运行
        2.abs relate ma,前一周期尝试使用close试试看(这样可能会符合常理一些(特别是针对上穿下穿之类的))

2025-03-04:
    已完成:
        1.思考如何快速找到关联性低的参数组合
        2.增加sol的逆向数据实盘运行
        3.增加负收益平均值与正收益平均值
        4.close的数据还不如之前的数据呢
    待完成:
        1.macross当前的价格有点问题，和当前的快慢线不够紧密。
        2.继续找出更好的一组正向和逆向数据，还有部分的close数据，如果独立性很好的话

2025-03-08:
    已完成:
        1.好参数的筛选指标:
            (origin_good_df['net_profit_rate'] > 200) and (origin_good_df['max_consecutive_loss'] > -10)
           直接按照profit_risk_score降序排序效果也比较好然后在大于100里面选择
        2.直接在较好的参数里面去选择相关性较低的参数组（最多支持1000个参数选择，再多就无法机选两两相关性了）
        3.增加独立性的预筛选，减小最终两两的计算量
    待完成：
        1.运行btc和其它的参数
        2.规范化整体的流程，提高可读性和可维护性

2025-03-09:
    已完成:
        1.优化独立性参数的生成，速度大大加快
    待完成：
        1.生成的组合太多了，应该如何选择。
        2.对后续的详细数据记录详细的df，然后用于统计后续的时间重叠情况，可用于选择出重叠情况,最终需要计算出 覆盖率 重叠率 重叠影响的利润。希望选择出覆盖率高但是重叠率低的参数组合。

2025-03-09:
    已完成:
        1.重新生成新的信号去寻找好的参数。
        2.优化回测的指标，增加fix_profit，这是重叠开平仓所对应的利润，减去它就可以得到实盘操作的利润
        3.优化回测的逻辑，增加速度，降低内存占用
    待完成：
        1.每个信号未来数据的预测。
        2.好指标的找寻（时间互补），都在一份代码上修改，不维护几份代码。


2025-03-12:
    已完成:
        1.增加指定信号详细回测数据的生成
        2.根据详细数据计算出相应的相关性与覆盖率
    待完成:
        1.结合覆盖率，交叉率来进行参数组的选择


2025-03-15:
    已完成:
        1.回测函数提前中止，减小不必要的运算。
    待完成:
        1.采用启发式算法，选择出好的参数组合。

2025-03-16:
    已完成:
        1.采用启发式算法(遗传算法)，选择出好的参数组合。
        2.能够灵活的调整适应性函数以选取不同的参数
    待完成:
        1.继续优化算法，提高效率，和效果

2025-03-20:
    已完成:
        1.感觉最好的策略还是应该是 monthly_net_profit_std_score足够小，同时选择对冲的组合。
    待完成:
        1.尝试对好的参数进行敏感性分析，进一步提高鲁棒性。
        2.尝试运行两个信号组合的结果。


2025-03-21:
    已完成:
        1.感觉都是对冲组合的功劳，对冲肯定是能够减小风险的方法，其它的化感觉就在max_consecutive_loss > -10里面最求利润最大化吧。
        2.(origin_good_df['avg_profit_rate'] > 100) 并且origin_good_df['net_profit_rate'] * origin_good_df['net_profit_rate'] / origin_good_df['hold_time_std'] 越大越好，这两个组合不错
        3.默认按照kai_count排序选择的化，可以在评分阶段除以kai_count避免评分高kai_count也大，最后只会选择一个
        4.avg也是越大越好,common也能够增加盈利的比例,而且common的时候差距比较好才更好（也就是趋势尽量一致）
    待完成:
        1.尝试对好的参数进行敏感性分析，进一步提高鲁棒性。
        2.尝试运行两个信号组合的结果。
        3.一一计算统计不同特征对结果稳定性的影响，最后在稳定的里面再选择对冲的
        4.思考完整的特征影响流程

2025-03-23:
    已完成:
        1.优化价格的范围，避免太小的值出现
        2.增加target指定信号生成回测结果
        3.发现kai_value（意思就是信号出现的个数）的值越大越好，这应该就是敏感性相关的参数
    待完成:
        1.思考完整的特征影响流程

2025-03-24:
    已完成:
        1.完成单变量和派生变量对利润影响的分析
    待完成:
        1.重新按照6个适应度函数取出好的参数

2025-03-25:
    已完成:
        1.感觉单变量影响不具有拓展性
        2.采用中庸之道，每个特征尽量保留中间的数据，最后就能够获取不错的数据
    待完成:
        1.继续探索中庸之道的方法，看看是否能够找到更好的参数


2025-03-26:
    已完成:
        1.发现在相关性分析的时候，相关性越小的pair中，出现个数越多，相关性越大的效果反而好（大概率原因是:因为池子里面的正数据更多，那么获取相关性小的数据就能够保证将坏的个体包含，同时坏的个体的平均相关度肯定更小）
        2.目前选择参数的逻辑: 1.先进行各个指标0.5展开筛选，筛选出每个特征都比较中间的池子。2.计算池子相互的关联性，然后重关联性小的pair，选择出平均关联性更大的个体。
        3.精简遗传算法代码
    待完成:
        1.继续探索中庸之道的方法，看看是否能够找到更好的参数
        2.直接运行部分币的好策略进行实盘操作。
        3.继续运行遗传算法，后续统计好的信号然后使用target获取更加详细的数据

2025-03-27:
    已完成:
        1.kai_count一变大，效果感觉就很差
        2.增加weekly维度的回测数据
    待完成:
        1.增加weekly维度的特征，进一步从相关度来选择策略组合

2025-03-28:
    已完成:
        1.重新保存所有中间的结果。
    待完成：
        1.可以分析同一个货币不同时间来找出稳定的指标。


2025-03-29:
    已完成:
        1.感觉可以直接考虑坏周期表现不错的策略，因为坏的表现不错那么在好行情也不太会亏
        2.优化validation
        3.策略间看起来确实存在周期性不同的偏向性，比如一个策略在一段时间表现很差，那么在另一段时间表现就会好很多。
    待完成：
        1.重新选定10个适应度函数的回测结果获取
        2.思考动态选择策略，大概思路是:因为策略有适应的周期，所有当目前该策略在最近的效果很差，那就说明可以增加选择它的概率，反之则减少选择它的概率。

2025-03-30:
    已完成:
        1.完成sol的10个适应度函数的回测结果获取
        2.简化ga_target的代码
    待完成：
        1.继续完成其它获取回测结果的获取
        2.运行相应的validatio函数，找到合适的参数
        3.运行完成之后，尝试动态选择策略


2025-03-31:
    已完成:
        1.完成btc的10个适应度函数的回测结果获取
    待完成：
        1.分析btc和sol的特征列是否能够通用

2025-04-09:
    已完成:
        1.确定好策略的最终路线:1.找出在不太时间不同货币上都表现不错的分箱 2.找到通用的能够提高平均利润的相关性分析策略 3.再验证动态选择策略是否有效 4.结合前面三种独立的优化方案进行最终测试
        2.完成指定区间详细数据的获取
    待完成：
        1.完成指定区间详细数据的获取（还未合并net_profit_rate_new等字段），可以考虑优化，将不同时间段的都放在一起，也可以加快后续analyse的逻辑
        2.找到好分箱对应的元素数据
        3.进行相关性策略的分析
        4.进行动态策略的分析

2025-04-10:
    已完成:
        1.规范详细的策略找寻流程，重新再找一遍
        2.之前的taget好像都计算成为了pepe的了，是个重大问题
        3.优化weekly_detail的存储方式
    待完成：
        1.适配相关性的计算逻辑，因为从dict变成了nparray


2025-04-12:
    已完成:
        1.进一步增加分析的特征
    待完成：
        1.完成所有false策略的回测


2025-04-13:
    已完成:
        1.完成5个币的false回测.
        2.完成好区间详细数据的获取

    待完成：
        1.完成所有false策略的回测
        2.进行相关性的策略找寻

2025-04-14:
    已完成:
        1.完成7个币的false回测.
        2.适配相关性的计算逻辑，因为从dict变成了nparray（只完成了filter适配，还有后面的未适配）

    待完成：
        1.完成所有false策略的回测
        2.进行相关性的策略找寻

2025-04-15:
    已完成:
        1.适配相关性的计算逻辑
    待完成：
        1.回测相关性的策略

2025-04-16:
    已完成:
        1.完成基于阈值和排序的相关性回测
    待完成：
        1.基于聚类的方法
        2.经典组合优化
        3.多目标优化
        4.基于图论的方法
        基于聚类的方法 (Clustering-Based):
        逻辑:
        使用策略相关性矩阵（或基于回测指标计算的特征距离）对策略进行聚类 (K-Means, Hierarchical Clustering)。目标是找出不同风险暴露类别的策略。
        从每个簇中选择代表性策略（例如，该簇中 Sharpe 最高的策略，或最接近簇中心的策略）。
        参数: 聚类算法, 聚类数量 K, 簇内选择标准。
        输出: 策略 ID 列表 (通常等权重，或按簇的质量/簇内代表策略的质量加权)。
        经典组合优化 (Portfolio Optimization):
        逻辑:
        最大化夏普比率 (Mean-Variance Optimization - MVO): 需要预期收益（用历史年化收益）、预期波动率（用历史年化波动率）和协方差矩阵（可从相关性矩阵和波动率计算得出）。
        最小化方差 (Global Minimum Variance - GMV): 只需协方差矩阵。
        风险平价 (Risk Parity): 使组合中每个策略的风险贡献大致相等。
        注意: MVO 对输入参数（尤其是预期收益）非常敏感。GMV 和 Risk Parity 相对稳健。
        参数: 优化目标, 约束条件 (如权重范围 0-1, 总和为 1, 最大单个策略权重)。
        输出: 策略 ID 列表和对应的优化权重。
        多目标优化 (Multi-Objective Optimization):
        逻辑: 同时优化多个目标，例如：最大化组合预期收益、最小化组合波动率、最小化组合最大回撤（近似）、最小化组合内平均相关性。
        使用 NSGA-II 等算法找到 Pareto 前沿。
        从 Pareto 前沿中选择一个解（例如，选择某个区域的折衷解，或满足特定约束的解）。
        参数: 优化目标, 优化算法参数, Pareto 前沿选择标准。
        输出: 策略 ID 列表和对应权重。
        基于图论的方法 (Graph-Based):
        逻辑:
        将策略视为图的节点。
        边的权重可以基于相关性（例如，权重 = 1 - abs(correlation)）。
        目标是找到一个“独立性”较好（低相关性）且节点“质量”较高（高 Sharpe）的子图。例如，寻找最大权重独立集 (Maximum Weight Independent Set) 的近似解。
        参数: 图的构建方式, 子图选择算法。
        输出: 策略 ID 列表 (通常等权重)。

2025-04-17:
    已完成:
        1.相关性回测的框架
    待完成：
        1.拓展更多的选择策略

2025-04-18:
    已完成:
        1.拓展更多的选择策略
    待完成：
        1.实盘运行好的策略
        2.继续true好策略的找寻

2025-04-20:
    已完成:
        1.需要将short和long进行分开统计处理
        2.整体的大概流程：
            1.ga遗传算法10个适应度函数找寻策略
            2.在测试集上获取已找寻策略的回测结果
            3.合并这两个数据，并且进行feature相关性分析
            4.找到表现都不错的分箱的相关策略，进行最终小集的回测数据获取
            5.计算分箱的相关性，然后以小集回测结果作为优化目标进行选择策略的找寻。
    待完成：
        1.重新运行一遍流程
        2.只差最后的相关性策略获取了

2025-04-21:
    已完成:
        1.运行相关性的选择策略
    待完成：
        1.相关性策略获取了

2025-04-23:
    已完成:
        1.维护a股量化交易的数据获取
    待完成：
        1.判断是否直接能够stock_zh_a_spot_em就实现之前的功能，这样的话拉取数据的时间会降到10s内

2025-04-25:
    已完成:
        1.确定每种币的选取逻辑：
            在获取了单独列分析与相关性分析后，每种币的选择策略为：
                找到平均线比较好的选择策略，然后找到每个币表现最好的具体策略作为它的最终策略
    待完成：
        1.尝试特定形态的捕捉（比如整体上涨或者下跌）
        2.动态变化选择策略

2025-04-26:
    已完成:
        1.再增加最后的相关性分析选择出最终策略
    待完成：
        1.将每个币的策略进行实盘运行
        2.梳理规范整体的流程，进行false方向策略的找寻。

2025-04-27:
    已完成:
        1.感觉之前找寻的逻辑不正确，因为相关性分布十分不均匀，所有分箱结果和后续相关性分析应该都不具有代表性
    待完成：
        1.ga之后先进行相关性去重

2025-04-28:
    已完成:
        1.以拓展性为目标重新回测数据
        2.整体流程:
            1.bread_through_strategy_ga.py进行数据回测得到详细的回测数据
    待完成：
        1.完成后续的流程与规范流程

2025-04-29:
    已完成:
        1.以拓展性为目标重新回测数据（BTC）
    待完成：
        1.完成后续的流程与规范流程


2025-04-30:
    已完成:
        1.以拓展性为目标重新回测数据（BTC）
    待完成：
        1.完成后续的流程与规范流程

2025-05-01:
    已完成:
        1.可以将is_reverse为True的策略也进行回测
    待完成：
        1.将is_reverse为True的策略也进行回测

2025-05-02:
    已完成:
        1.进行部分币种实盘操作
        2.验证部分反向信号的计算
    待完成：
        1.完成所有币的回测以及好策略筛选
        2.适配其它有问题的信号类型['macross', 'rsi', 'macd', 'cci', 'atr']

2025-05-02:
    已完成:
        1.完成统一的run实盘操作
    待完成：
        1.跑完所有的币种，进行最终的运行

2025-05-05:
    已完成:
        1.完成统一的run实盘操作
        2.感觉false情况下的策略不怎么好。
    待完成：
        1.跑完所有的币种，进行最终的运行
        2.规范当前的流程
        3.拉取更长的数据进行回测，希望能够尽量覆盖到所有的行情,而且优化回测的速度（分段进行回测，以每一年为一个周期，满足要求的才进入下一年的回测，这样就能够大大减小计算量）



2025-05-06:
    已完成:
        1.增加按照年份进行回测，减小计算量
        2.探索新的方案（1.遗传编程：这个和当前的ga是差不多的，只是更加灵活，而且感觉过拟合的可能性更大 2.强化学习 ）
    待完成：
        1.适配后续流程，而且速度有点慢
        2.优化第一次的精简op函数，减小不必要的计算


2025-05-07:
    已完成:
        1.增加强化学习大概代码（还需优化，效果不好）
    待完成：
        1.继续分层ga
        2.优化强化学习代码